{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data/road_alpine-1_7cars_2475231.csv\n",
      "train_data/road_alpine-1_7cars_2475119.csv\n",
      "train_data/road_alpine-1_7cars_2481619.csv\n",
      "train_data/road_alpine-1_7cars_2481544.csv\n",
      "train_data/road_alpine-1_7cars_2475043.csv\n",
      "train_data/road_alpine-1_7cars_2475155.csv\n",
      "train_data/road_alpine-1_7cars_2481731.csv\n",
      "train_data/road_alpine-1_7cars_2481655.csv\n",
      "train_data/road_alpine-1_7cars_2481432.csv\n",
      "train_data/road_alpine-1_7cars_2481842.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accel</th>\n",
       "      <th>brake</th>\n",
       "      <th>steer</th>\n",
       "      <th>angle</th>\n",
       "      <th>curLapTime</th>\n",
       "      <th>distFromStart</th>\n",
       "      <th>distRaced</th>\n",
       "      <th>gear</th>\n",
       "      <th>lastLapTime</th>\n",
       "      <th>racePos</th>\n",
       "      <th>...</th>\n",
       "      <th>oppos26</th>\n",
       "      <th>oppos27</th>\n",
       "      <th>oppos28</th>\n",
       "      <th>oppos29</th>\n",
       "      <th>oppos30</th>\n",
       "      <th>oppos31</th>\n",
       "      <th>oppos32</th>\n",
       "      <th>oppos33</th>\n",
       "      <th>oppos34</th>\n",
       "      <th>oppos35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019920e-07</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>6306.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019920e-07</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>6306.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019920e-07</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>6306.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019920e-07</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>6306.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019920e-07</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>6306.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accel  brake  steer         angle  curLapTime  distFromStart  distRaced  \\\n",
       "0    1.0    0.0    0.0  3.019920e-07      -0.982        6306.65        0.0   \n",
       "1    1.0    0.0    0.0  3.019920e-07      -0.962        6306.65        0.0   \n",
       "2    1.0    0.0    0.0  3.019920e-07      -0.942        6306.65        0.0   \n",
       "3    1.0    0.0    0.0  3.019920e-07      -0.922        6306.65        0.0   \n",
       "4    1.0    0.0    0.0  3.019920e-07      -0.902        6306.65        0.0   \n",
       "\n",
       "   gear  lastLapTime  racePos   ...     oppos26  oppos27  oppos28  oppos29  \\\n",
       "0     0          0.0        7   ...       200.0    200.0    200.0    200.0   \n",
       "1     0          0.0        7   ...       200.0    200.0    200.0    200.0   \n",
       "2     0          0.0        7   ...       200.0    200.0    200.0    200.0   \n",
       "3     0          0.0        7   ...       200.0    200.0    200.0    200.0   \n",
       "4     0          0.0        7   ...       200.0    200.0    200.0    200.0   \n",
       "\n",
       "   oppos30  oppos31  oppos32  oppos33  oppos34  oppos35  \n",
       "0    200.0    200.0    200.0    200.0    200.0    200.0  \n",
       "1    200.0    200.0    200.0    200.0    200.0    200.0  \n",
       "2    200.0    200.0    200.0    200.0    200.0    200.0  \n",
       "3    200.0    200.0    200.0    200.0    200.0    200.0  \n",
       "4    200.0    200.0    200.0    200.0    200.0    200.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tracknames = os.listdir(\"/home/jasper-ubuntu/Documents/Studie/Master AI/Computational intelligence/Torcs-CI/CI/train_data/\")\n",
    "# tracknames = ['aalborg.csv']\n",
    "datadictin = {}\n",
    "datadictout = {}\n",
    "datadict = {}\n",
    "framesin =[]\n",
    "framesout=[]\n",
    "data = []\n",
    "\n",
    "for i, file in  enumerate(tracknames):\n",
    "    path = os.path.join('train_data', file)\n",
    "    print(path)\n",
    "    datadictin[i] = pd.read_csv(path,sep=';', index_col=False).iloc[:-1, 3:]\n",
    "    datadictout[i] = pd.read_csv(path,sep=';', index_col=False).iloc[:-1, 0:3]\n",
    "    datadict[i]=pd.read_csv(path,sep=';', index_col=False).iloc[:,:]\n",
    "\n",
    "#Concatenate all datasets\n",
    "for i,file in enumerate(tracknames):\n",
    "    framesin.append(datadictin[i])\n",
    "    framesout.append(datadictout[i])\n",
    "    data.append(datadict[i])\n",
    "    \n",
    "inp = pd.concat(framesin) \n",
    "outp = pd.concat(framesout) \n",
    "train = pd.concat(data)\n",
    "\n",
    "#Drop missing values\n",
    "inp.replace('', np.nan, inplace=True)\n",
    "inp.dropna(inplace=True)\n",
    "\n",
    "outp.replace('', np.nan, inplace=True)\n",
    "outp.dropna(inplace=True)\n",
    "\n",
    "train.replace('', np.nan, inplace=True)\n",
    "train.dropna(inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331770 72 3\n"
     ]
    }
   ],
   "source": [
    "input_size = inp.shape[1]\n",
    "output_size = outp.shape[1]\n",
    "datapoints = inp.shape[0]\n",
    "print(datapoints,input_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "input_size = inp.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = outp.shape[1]\n",
    "num_epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural Network Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.tanh(self.fc1(x))\n",
    "        h = F.tanh(self.fc2(h))\n",
    "        h = F.tanh(self.fc3(h))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def minibatch(data, batch_size=32):\n",
    "#     for i in range(0, len(data), batch_size):\n",
    "#         yield data[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable(data, labels = False):\n",
    "    \"\"\"Get a Variable given data (pandas dataframe)\"\"\"\n",
    "    # Use float (not double) for better precission: (see reply of smth)\n",
    "    # https://discuss.pytorch.org/t/problems-with-target-arrays-of-int-int32-types-in-loss-functions/140/3\n",
    "    \n",
    "    # Labels need to be long to work (for cross entropy, for MSE they both need to be long)\n",
    "    if labels:\n",
    "        tensor = torch.from_numpy(data.iloc[:,:].as_matrix()).float()\n",
    "    else:\n",
    "        tensor = torch.from_numpy(data.iloc[:,:].as_matrix()).float()\n",
    "#     print(tensor)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    \"\"\" ... \"\"\"\n",
    "\n",
    "    x = batch.iloc[:-1, 3:]\n",
    "    y = batch.iloc[:-1, 0:3]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: avg train loss=0.0530, time=41.49s\n",
      "iter 1: avg train loss=0.0521, time=43.74s\n",
      "iter 2: avg train loss=0.0518, time=40.25s\n",
      "iter 3: avg train loss=0.0526, time=37.70s\n",
      "iter 4: avg train loss=0.0530, time=37.45s\n",
      "iter 5: avg train loss=0.0525, time=55.67s\n",
      "iter 6: avg train loss=0.0532, time=44.90s\n",
      "iter 7: avg train loss=0.0528, time=43.10s\n",
      "iter 8: avg train loss=0.0526, time=38.77s\n",
      "iter 9: avg train loss=0.0528, time=38.77s\n",
      "iter 10: avg train loss=0.0526, time=39.77s\n",
      "iter 11: avg train loss=0.0528, time=40.91s\n",
      "iter 12: avg train loss=0.0526, time=41.27s\n",
      "iter 13: avg train loss=0.0532, time=39.13s\n",
      "iter 14: avg train loss=0.0529, time=38.70s\n",
      "iter 15: avg train loss=0.0528, time=38.35s\n",
      "iter 16: avg train loss=0.0530, time=40.31s\n",
      "iter 17: avg train loss=0.0529, time=55.48s\n",
      "iter 18: avg train loss=0.0528, time=64.30s\n",
      "iter 19: avg train loss=0.0528, time=66.90s\n"
     ]
    }
   ],
   "source": [
    "for ITER in range(num_epochs):\n",
    "    \n",
    "    # Take a random sample of size batchsize\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    updates = 0\n",
    "\n",
    "    for i in range(int(datapoints/(batch_size))):\n",
    "        batch = train.sample(n = batch_size)\n",
    "        updates += 1\n",
    "\n",
    "        # pad data with zeros\n",
    "        x, y = preprocess(batch)\n",
    "        \n",
    "        # forward pass\n",
    "        scores = model(get_variable(x))\n",
    "        targets = get_variable(y, labels= True)\n",
    "        loss = nn.MSELoss()\n",
    "        output = loss(scores, targets)\n",
    "        train_loss += output.data[0]\n",
    "\n",
    "        # backward pass\n",
    "        model.zero_grad()\n",
    "        output.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"iter %r: avg train loss=%.4f, time=%.2fs\" %\n",
    "          (ITER, train_loss/updates, time.time()-start))\n",
    "\n",
    "    # evaluate\n",
    "#     _, _, acc_train = evaluate(model, train)\n",
    "#     _, _, acc_dev = evaluate(model, dev)\n",
    "#     print(\"iter %r: train acc=%.4f  test acc=%.4f\" % (ITER, acc_train, acc_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "     0.0009     10.3680    561.8210  ...     200.0000    200.0000    200.0000\n",
      "    -0.1226      9.3880    517.5990  ...     200.0000    200.0000    200.0000\n",
      "     0.0871     16.2580    613.1340  ...     200.0000    200.0000    200.0000\n",
      "                ...                   ⋱                   ...                \n",
      "     0.0906     66.5700   3094.0701  ...     200.0000    200.0000    200.0000\n",
      "     0.0636     87.9220   3543.2000  ...     200.0000    200.0000    200.0000\n",
      "     0.4401     50.6260   2395.4299  ...     200.0000    200.0000    200.0000\n",
      "[torch.FloatTensor of size 99x72]\n",
      "\n",
      "Variable containing:\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8839  0.0457 -0.0362\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8558  0.0140 -0.0034\n",
      " 0.8234  0.0362  0.0117\n",
      " 0.8558  0.0140 -0.0034\n",
      "[torch.FloatTensor of size 99x3]\n",
      "\n",
      "          accel     brake     steer\n",
      "18525  1.000000  0.000000  0.056080\n",
      "18476  1.000000  0.000000 -0.036835\n",
      "29780  1.000000  0.000000 -0.004509\n",
      "23659  1.000000  0.000000  0.004442\n",
      "27254  1.000000  0.000000 -0.000004\n",
      "30503  1.000000  0.000000  0.187718\n",
      "14484  1.000000  0.000000  0.004912\n",
      "2572   1.000000  0.000000 -0.023665\n",
      "13311  1.000000  0.000000  0.017743\n",
      "27953  0.644150  0.000000 -0.007760\n",
      "15891  1.000000  0.000000  0.044766\n",
      "28138  1.000000  0.000000 -0.277585\n",
      "14369  1.000000  0.000000  0.081603\n",
      "880    1.000000  0.000000 -0.022343\n",
      "26529  1.000000  0.000000  0.030364\n",
      "3390   1.000000  0.000000 -0.025021\n",
      "10825  1.000000  0.000000 -0.007675\n",
      "2867   0.019054  0.000000 -0.088392\n",
      "32748  1.000000  0.000000  0.239584\n",
      "31435  1.000000  0.000000 -0.123012\n",
      "23015  1.000000  0.000000  0.030651\n",
      "11395  1.000000  0.000000 -0.025956\n",
      "14237  0.417541  0.000000  0.282483\n",
      "28662  0.000000  0.709134  0.235488\n",
      "14101  1.000000  0.000000  0.020283\n",
      "10712  1.000000  0.000000 -0.025023\n",
      "6972   1.000000  0.000000 -0.076556\n",
      "17649  0.796489  0.000000  0.146556\n",
      "11397  1.000000  0.000000 -0.014880\n",
      "27616  1.000000  0.000000  0.003311\n",
      "...         ...       ...       ...\n",
      "243    1.000000  0.000000  0.006029\n",
      "31865  1.000000  0.000000 -0.041433\n",
      "4576   1.000000  0.000000  0.013463\n",
      "590    0.000000  0.108255 -0.165923\n",
      "16661  1.000000  0.000000 -0.006058\n",
      "21894  1.000000  0.000000  0.000088\n",
      "6406   1.000000  0.000000 -0.024249\n",
      "18079  1.000000  0.000000 -0.000764\n",
      "31090  1.000000  0.000000  0.018919\n",
      "24075  0.588580  0.000000 -0.591307\n",
      "14849  0.441266  0.000000 -0.325116\n",
      "6356   1.000000  0.000000  0.000309\n",
      "23190  1.000000  0.000000 -0.012800\n",
      "32639  1.000000  0.000000  0.094824\n",
      "32     1.000000  0.000000  0.000000\n",
      "11561  1.000000  0.000000  0.010671\n",
      "24936  1.000000  0.000000  0.012436\n",
      "6991   1.000000  0.000000  0.164536\n",
      "19581  1.000000  0.000000 -0.035155\n",
      "32275  1.000000  0.000000  0.038766\n",
      "12517  1.000000  0.000000  0.003469\n",
      "17690  1.000000  0.000000  0.193871\n",
      "26010  0.825396  0.000000  0.030437\n",
      "24366  1.000000  0.000000 -0.041198\n",
      "8371   1.000000  0.000000  0.035267\n",
      "19926  0.201265  0.000000  0.576901\n",
      "10744  1.000000  0.000000  0.008013\n",
      "9795   1.000000  0.000000  0.036273\n",
      "4235   1.000000  0.000000  0.064156\n",
      "14836  0.290881  0.000000 -0.387695\n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Test prediction\n",
    "testval = get_variable(x)\n",
    "print(testval)\n",
    "print(model(testval))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper-ubuntu/miniconda3/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "save_path_model = 'simple_ff_model_20epochs_batch100.pt'\n",
    "save_path_dict = 'simple_ff_DICT_20epochs_batch100_dict_hiden_size50_2HL_INP72_outp3_Forward_tanh_tanh_tanh.pt'\n",
    "# https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n",
    "torch.save(model, save_path_model)\n",
    "torch.save(model.state_dict(),save_path_dict)\n",
    "# model.save_state_dict('trainedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
