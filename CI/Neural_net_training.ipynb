{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data/road_alpine-1_7cars_2475231.csv\n",
      "train_data/road_alpine-1_7cars_2475119.csv\n",
      "train_data/road_alpine-1_7cars_2475043.csv\n",
      "train_data/road_alpine-1_7cars_2475155.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accel</th>\n",
       "      <th>brake</th>\n",
       "      <th>steer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accel  brake  steer\n",
       "0    1.0    0.0    0.0\n",
       "1    1.0    0.0    0.0\n",
       "2    1.0    0.0    0.0\n",
       "3    1.0    0.0    0.0\n",
       "4    1.0    0.0    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tracknames = os.listdir(\"/home/jasper-ubuntu/Documents/Studie/Master AI/Computational intelligence/Torcs-CI/CI/train_data/\")\n",
    "# tracknames = ['aalborg.csv']\n",
    "datadictin = {}\n",
    "datadictout = {}\n",
    "framesin =[]\n",
    "framesout=[]\n",
    "for i, file in  enumerate(tracknames):\n",
    "    path = os.path.join('train_data', file)\n",
    "    print(path)\n",
    "    datadictin[i] = pd.read_csv(path,sep=';', index_col=False).iloc[:-1, 3:]\n",
    "    datadictout[i] = pd.read_csv(path,sep=';', index_col=False).iloc[:-1, 0:3]\n",
    "\n",
    "\n",
    "#Concatenate all datasets\n",
    "for i,file in enumerate(tracknames):\n",
    "    framesin.append(datadictin[i])\n",
    "    framesout.append(datadictout[i])\n",
    "    \n",
    "inp = pd.concat(framesin) \n",
    "outp = pd.concat(framesout) \n",
    "\n",
    "outp.head()\n",
    "\n",
    "#Drop missing values\n",
    "inp.replace('', np.nan, inplace=True)\n",
    "inp.dropna(inplace=True)\n",
    "outp.replace('', np.nan, inplace=True)\n",
    "outp.dropna(inplace=True)\n",
    "outp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make 1 axis of brake and accelaration\n",
    "# outp.loc[:,'BRAKE'] *= -1\n",
    "# outp.iloc[:5,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCELERATION</th>\n",
       "      <th>BRAKE</th>\n",
       "      <th>STEERING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACCELERATION  BRAKE  STEERING\n",
       "0             1    0.0 -0.002715\n",
       "1             1    0.0 -0.002715\n",
       "2             1    0.0 -0.002715\n",
       "3             1    0.0 -0.002715\n",
       "4             1    0.0 -0.002715"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maxCol= lambda x: max(x.min(), x.max(), key=abs)\n",
    "# outp.iloc[:,0:2].apply(maxCol,axis=1)\n",
    "\n",
    "# outp['brake_acceleration'] = pd.Series(max(abs(outp.iloc[:,0:2])))\n",
    "outp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132708 72 3\n"
     ]
    }
   ],
   "source": [
    "colsin = inp.shape[1]\n",
    "colsout = outp.shape[1]\n",
    "datapoints = inp.shape[0]\n",
    "print(datapoints,colsin,colsout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "     0.0000     -0.9820   6306.6499  ...     200.0000    200.0000    200.0000\n",
      "     0.0000     -0.9620   6306.6499  ...     200.0000    200.0000    200.0000\n",
      "     0.0000     -0.9420   6306.6499  ...     200.0000    200.0000    200.0000\n",
      "                ...                   ⋱                   ...                \n",
      "    -0.0359     90.9260   2000.6600  ...     200.0000    200.0000    200.0000\n",
      "    -0.0366     90.9480   2000.9600  ...     200.0000    200.0000    200.0000\n",
      "    -0.0363     90.9700   2001.2700  ...     200.0000    200.0000    200.0000\n",
      "[torch.FloatTensor of size 132708x72]\n",
      "\n",
      "Variable containing:\n",
      " 1.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0000\n",
      "           ⋮            \n",
      " 1.0000  0.0000 -0.0226\n",
      " 1.0000  0.0000 -0.0759\n",
      " 1.0000  0.0000 -0.0557\n",
      "[torch.FloatTensor of size 132708x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get data from pandas in a Tensor Variable\n",
    "x = Variable(torch.from_numpy(inp.iloc[:,:].as_matrix()).float())\n",
    "y = Variable(torch.from_numpy(outp.iloc[:,:].as_matrix()).float())\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        \n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y = self.linear2(h_relu)\n",
    "        y_pred = F.tanh(y)\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "class LSTMNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(LSTMNeuralNet, self).__init__()\n",
    "        self.hidden_dim = H\n",
    "        \n",
    "        self.recurrent = nn.LSTM(D_in, H)\n",
    "        self.linear = nn.Linear(H, D_out)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        \"\"\"\n",
    "        Before we've done anything, we dont have any hidden state.\n",
    "        Refer to the Pytorch documentation to see exactly\n",
    "        why they have this dimensionality.\n",
    "        The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        return (torch.autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                torch.autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        lstm_out, self.hidden = self.recurrent(x, self.hidden)\n",
    "        y = self.linear(lstm_out)\n",
    "        y_pred = F.tanh(y)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    \n",
    "# Neural Network Model (1 hidden layer)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.sigmoid(self.fc1(x))\n",
    "        out = F.sigmoid(self.fc2(out))\n",
    "        out = F.tanh(self.fc3(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(GRUNeuralNet, self).__init__()\n",
    "        self.hidden_dim = H\n",
    "        \n",
    "\n",
    "        self.linear = nn.Linear(H, D_out)\n",
    "            self.recurrent = nn.GRU(D_in, H, 1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        \"\"\"\n",
    "        Before we've done anything, we dont have any hidden state.\n",
    "        Refer to the Pytorch documentation to see exactly\n",
    "        why they have this dimensionality.\n",
    "        The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        return (torch.autograd.Variable(torch.zeros(self.hidden_dim, 1, h_layer_size )))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        lstm_out, self.hidden = self.recurrent(x, self.hidden)\n",
    "        y = self.linear(lstm_out)\n",
    "        y_pred = F.tanh(y)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "learning rate : 1.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: dimension 1 out of range of 1D tensor at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-382e89495fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Forward to get output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Calculate Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-69d00e3c06d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mwell\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marbitrary\u001b[0m \u001b[0moperators\u001b[0m \u001b[0mon\u001b[0m \u001b[0mVariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: dimension 1 out of range of 1D tensor at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:24"
     ]
    }
   ],
   "source": [
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "# TODO: We doen niets met Batch size..\n",
    "N, D_in, H, D_out = 50, colsin, 50, colsout\n",
    "\n",
    "net = RecurrentNeuralNet(D_in, H, D_out)\n",
    "\n",
    "# mean square error criterion for regression Euclidian distance\n",
    "criterion = nn.MSELoss()\n",
    "# criterion.sizeAverage = False\n",
    "\n",
    "# L1 norm , Manhatan distance\n",
    "# criterion = nn.L1Loss()\n",
    "\n",
    "# optimizer = torch.optim.ASGD(net.parameters(), lr=learning_rate)# , momentum=0.9)\n",
    "lr=0.6\n",
    "optimizer = torch.optim.SGD([\n",
    "                {'params': net.parameters(), 'lr': lr}\n",
    "            ], lr=lr )# , momentum=0.1)\n",
    "\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "end=True\n",
    "test=1\n",
    "# Train the Model\n",
    "for epoch in range(15):\n",
    "   # adjust_learning_rate(optimizer,epoch,lr)\n",
    "    print(\"epoch : \"+str(epoch))\n",
    "    if test>0.0001:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr**epoch\n",
    "        test=lr**epoch\n",
    "    elif end:\n",
    "        end=Flase\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.0001\n",
    "        test=0.0001\n",
    "    print(\"learning rate : \"+str(test))\n",
    "    #print (optimizer.param_group['lr'])\n",
    "    for i in range(colsin):\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        # optimizer.zero_grad()\n",
    "        # Forward to get output\n",
    "        out = net(x[i])\n",
    "        # Calculate Loss\n",
    "        loss = criterion(out, y[i])\n",
    "        # print(out[0] - loss[0])\n",
    "        # print(loss)\n",
    "        net.zero_grad()\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "#print(\"iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: dimension 1 out of range of 1D tensor at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-64a6d88f3d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Forward pass: Compute predicted y by passing x to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Compute and print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-c4665aba9c2e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mwell\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marbitrary\u001b[0m \u001b[0moperators\u001b[0m \u001b[0mon\u001b[0m \u001b[0mVariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mchunk\u001b[0;34m(self, num_chunks, dim)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, num_chunks, dim)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mchunk\u001b[0;34m(self, n_chunks, dim)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mchunk\u001b[0;34m(tensor, chunks, dim)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0msplit_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: dimension 1 out of range of 1D tensor at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:24"
     ]
    }
   ],
   "source": [
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "\n",
    "learning_rate = 1e-4\n",
    "net = GRUNeuralNet(D_in, H, D_out)\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-4)\n",
    "for t in range(15):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = net(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "   -1     1     1\n",
      "[torch.FloatTensor of size 300x3]\n",
      " Variable containing:\n",
      " 1.0000  0.0000 -0.0322\n",
      " 1.0000  0.0000 -0.0327\n",
      " 1.0000  0.0000 -0.0331\n",
      " 1.0000  0.0000 -0.0332\n",
      " 1.0000  0.0000 -0.0329\n",
      " 1.0000  0.0000 -0.0326\n",
      " 1.0000  0.0000 -0.0322\n",
      " 1.0000  0.0000 -0.0313\n",
      " 1.0000  0.0000 -0.0304\n",
      " 1.0000  0.0000 -0.0297\n",
      " 1.0000  0.0000 -0.0286\n",
      " 1.0000  0.0000 -0.0274\n",
      " 1.0000  0.0000 -0.0266\n",
      " 1.0000  0.0000 -0.0253\n",
      " 1.0000  0.0000 -0.0241\n",
      " 1.0000  0.0000 -0.0232\n",
      " 1.0000  0.0000 -0.0218\n",
      " 1.0000  0.0000 -0.0207\n",
      " 1.0000  0.0000 -0.0199\n",
      " 1.0000  0.0000 -0.0185\n",
      " 1.0000  0.0000 -0.0174\n",
      " 1.0000  0.0000 -0.0240\n",
      " 1.0000  0.0000 -0.0181\n",
      " 1.0000  0.0000 -0.0154\n",
      " 1.0000  0.0000 -0.0142\n",
      " 1.0000  0.0000 -0.0126\n",
      " 1.0000  0.0000 -0.0115\n",
      " 1.0000  0.0000 -0.0109\n",
      " 1.0000  0.0000 -0.0532\n",
      " 1.0000  0.0000 -0.0288\n",
      " 1.0000  0.0000 -0.0173\n",
      " 1.0000  0.0000 -0.0124\n",
      " 1.0000  0.0000 -0.0099\n",
      " 1.0000  0.0000 -0.0081\n",
      " 1.0000  0.0000 -0.0061\n",
      " 1.0000  0.0000 -0.0049\n",
      " 1.0000  0.0000 -0.0038\n",
      " 1.0000  0.0000 -0.0025\n",
      " 1.0000  0.0000 -0.0018\n",
      " 1.0000  0.0000 -0.0012\n",
      " 1.0000  0.0000 -0.0004\n",
      " 1.0000  0.0000 -0.0000\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0016\n",
      " 1.0000  0.0000  0.0016\n",
      " 1.0000  0.0000  0.0017\n",
      " 1.0000  0.0000  0.0018\n",
      " 1.0000  0.0000  0.0018\n",
      " 1.0000  0.0000  0.0018\n",
      " 1.0000  0.0000  0.0017\n",
      " 1.0000  0.0000  0.0020\n",
      " 1.0000  0.0000  0.0018\n",
      " 1.0000  0.0000  0.0016\n",
      " 1.0000  0.0000  0.0020\n",
      " 1.0000  0.0000  0.0017\n",
      " 1.0000  0.0000  0.0021\n",
      " 1.0000  0.0000  0.0017\n",
      " 1.0000  0.0000  0.0014\n",
      " 1.0000  0.0000  0.0021\n",
      " 1.0000  0.0000  0.0015\n",
      " 1.0000  0.0000  0.0014\n",
      " 1.0000  0.0000  0.0019\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0021\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0010\n",
      " 1.0000  0.0000  0.0021\n",
      " 1.0000  0.0000  0.0012\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0020\n",
      " 1.0000  0.0000  0.0011\n",
      " 1.0000  0.0000  0.0020\n",
      " 1.0000  0.0000  0.0010\n",
      " 1.0000  0.0000  0.0007\n",
      " 1.0000  0.0000  0.0018\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0015\n",
      " 1.0000  0.0000  0.0011\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0016\n",
      " 1.0000  0.0000  0.0007\n",
      " 1.0000  0.0000  0.0012\n",
      " 1.0000  0.0000  0.0008\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0011\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0002\n",
      " 1.0000  0.0000  0.0007\n",
      " 1.0000  0.0000  0.0001\n",
      " 1.0000  0.0000  0.0002\n",
      " 1.0000  0.0000  0.0002\n",
      " 1.0000  0.0000  0.0001\n",
      " 1.0000  0.0000  0.0001\n",
      " 1.0000  0.0000 -0.0000\n",
      " 1.0000  0.0000 -0.0004\n",
      " 1.0000  0.0000 -0.0002\n",
      " 1.0000  0.0000 -0.0007\n",
      " 1.0000  0.0000 -0.0003\n",
      " 1.0000  0.0000 -0.0004\n",
      " 1.0000  0.0000 -0.0009\n",
      " 1.0000  0.0000 -0.0005\n",
      " 1.0000  0.0000 -0.0011\n",
      " 1.0000  0.0000 -0.0007\n",
      " 1.0000  0.0000 -0.0013\n",
      " 1.0000  0.0000 -0.0009\n",
      " 1.0000  0.0000 -0.0006\n",
      " 1.0000  0.0000 -0.0014\n",
      " 1.0000  0.0000 -0.0009\n",
      " 1.0000  0.0000 -0.0016\n",
      " 1.0000  0.0000 -0.0010\n",
      " 1.0000  0.0000 -0.0006\n",
      " 1.0000  0.0000 -0.0019\n",
      " 1.0000  0.0000 -0.0009\n",
      " 1.0000  0.0000 -0.0017\n",
      " 1.0000  0.0000 -0.0011\n",
      " 1.0000  0.0000 -0.0018\n",
      " 1.0000  0.0000 -0.0013\n",
      " 1.0000  0.0000 -0.0007\n",
      " 1.0000  0.0000 -0.0017\n",
      " 1.0000  0.0000 -0.0013\n",
      " 1.0000  0.0000 -0.0019\n",
      " 1.0000  0.0000 -0.0013\n",
      " 1.0000  0.0000 -0.0007\n",
      " 1.0000  0.0000 -0.0017\n",
      " 1.0000  0.0000 -0.0012\n",
      " 1.0000  0.0000 -0.0018\n",
      " 1.0000  0.0000 -0.0012\n",
      " 1.0000  0.0000 -0.0006\n",
      " 1.0000  0.0000 -0.0015\n",
      " 1.0000  0.0000 -0.0011\n",
      " 1.0000  0.0000 -0.0015\n",
      " 1.0000  0.0000 -0.0006\n",
      " 1.0000  0.0000 -0.0007\n",
      " 1.0000  0.0000 -0.0012\n",
      " 1.0000  0.0000 -0.0009\n",
      " 1.0000  0.0000 -0.0010\n",
      " 1.0000  0.0000 -0.0003\n",
      " 1.0000  0.0000 -0.0005\n",
      " 1.0000  0.0000 -0.0006\n",
      " 1.0000  0.0000 -0.0004\n",
      " 1.0000  0.0000 -0.0004\n",
      " 1.0000  0.0000 -0.0001\n",
      " 1.0000  0.0000 -0.0003\n",
      " 1.0000  0.0000 -0.0001\n",
      " 1.0000  0.0000 -0.0002\n",
      " 1.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0002\n",
      " 1.0000  0.0000 -0.0001\n",
      " 1.0000  0.0000  0.0002\n",
      " 1.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0003\n",
      " 1.0000  0.0000  0.0001\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0003\n",
      " 1.0000  0.0000  0.0007\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0010\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0010\n",
      " 1.0000  0.0000  0.0008\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0007\n",
      " 1.0000  0.0000  0.0015\n",
      " 1.0000  0.0000  0.0007\n",
      " 1.0000  0.0000  0.0008\n",
      " 1.0000  0.0000  0.0012\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0014\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0013\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0010\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0012\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0015\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0012\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0011\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0011\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0005\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0006\n",
      " 1.0000  0.0000  0.0010\n",
      " 1.0000  0.0000  0.0003\n",
      " 1.0000  0.0000  0.0011\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0009\n",
      " 1.0000  0.0000  0.0003\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0004\n",
      " 1.0000  0.0000  0.0001\n",
      " 1.0000  0.0000  0.0002\n",
      " 1.0000  0.0000 -0.0000\n",
      " 1.0000  0.0000 -0.0004\n",
      " 1.0000  0.0000 -0.0003\n",
      " 1.0000  0.0000 -0.0011\n",
      " 1.0000  0.0000 -0.0006\n",
      " 1.0000  0.0000 -0.0020\n",
      " 1.0000  0.0000 -0.0007\n",
      " 1.0000  0.0000 -0.0024\n",
      " 1.0000  0.0000 -0.0010\n",
      " 1.0000  0.0000 -0.0027\n",
      " 1.0000  0.0000 -0.0011\n",
      " 1.0000  0.0000 -0.0029\n",
      " 1.0000  0.0000 -0.0012\n",
      " 1.0000  0.0000 -0.0010\n",
      " 1.0000  0.0000 -0.0082\n",
      " 1.0000  0.0000 -0.0031\n",
      " 1.0000  0.0000 -0.0132\n",
      " 1.0000  0.0000 -0.0173\n",
      " 1.0000  0.0000 -0.0072\n",
      " 1.0000  0.0000 -0.0038\n",
      " 0.0000  0.7390 -0.0173\n",
      " 0.0000  0.1000 -0.0164\n",
      " 0.0000  0.7268 -0.0296\n",
      " 1.0000  0.0000 -0.0197\n",
      " 1.0000  0.0000 -0.0261\n",
      " 0.0000  0.7174 -0.0100\n",
      " 0.0000  0.1823 -0.0348\n",
      " 0.0000  0.7054 -0.0333\n",
      " 1.0000  0.0000 -0.0486\n",
      " 1.0000  0.0000 -0.0247\n",
      " 0.0000  0.6959 -0.0095\n",
      " 1.0000  0.0000 -0.0432\n",
      " 0.9825  0.0000 -0.0302\n",
      " 0.7904  0.0000 -0.0380\n",
      " 0.0000  0.6887 -0.0208\n",
      " 0.5758  0.0000 -0.0578\n",
      " 0.5479  0.0000 -0.0419\n",
      " 0.3565  0.0000 -0.0485\n",
      " 0.0000  0.6797 -0.0291\n",
      " 0.2019  0.0000 -0.0312\n",
      " 0.1575  0.0000 -0.0604\n",
      " 0.0000  0.6699 -0.0253\n",
      " 0.0000  0.4558 -0.0671\n",
      " 0.0170  0.0000 -0.0746\n",
      " 0.0000  0.6542 -0.0447\n",
      " 0.0000  0.6036 -0.0249\n",
      " 0.0166  0.0000 -0.0748\n",
      " 0.0028  0.0000 -0.0654\n",
      " 0.0000  0.6365 -0.0911\n",
      " 0.0000  0.6312 -0.0849\n",
      " 0.0000  0.5471 -0.0667\n",
      " 0.0000  0.2527 -0.1068\n",
      " 0.0000  0.6117 -0.1261\n",
      " 0.0000  0.1000 -0.1870\n",
      " 0.0000  0.6019 -0.1631\n",
      " 0.0000  0.5968 -0.1713\n",
      " 0.0000  0.1165 -0.1552\n",
      " 0.0000  0.5860 -0.1735\n",
      " 0.0000  0.1000 -0.2358\n",
      " 0.0000  0.5776 -0.2239\n",
      " 0.0000  0.5727 -0.1743\n",
      " 0.0000  0.1000 -0.2232\n",
      " 0.0000  0.5626 -0.2266\n",
      " 0.0000  0.1000 -0.2929\n",
      " 0.4464  0.0000 -0.2862\n",
      " 0.0000  0.5534 -0.2159\n",
      " 0.4866  0.0000 -0.2511\n",
      " 0.4807  0.0000 -0.2114\n",
      " 0.4085  0.0000 -0.1826\n",
      " 0.3038  0.0000 -0.2221\n",
      " 0.2338  0.0000 -0.1852\n",
      " 0.1687  0.0000 -0.1202\n",
      " 0.1740  0.0000 -0.1422\n",
      " 0.1224  0.0000 -0.0955\n",
      " 0.0766  0.0000 -0.0785\n",
      " 0.0000  0.5400 -0.1317\n",
      " 0.0000  0.5367 -0.1220\n",
      " 0.0829  0.0000 -0.1861\n",
      " 0.0577  0.0000 -0.1502\n",
      " 0.0398  0.0000 -0.0987\n",
      " 0.0000  0.1083 -0.1659\n",
      " 0.0000  0.5018 -0.1451\n",
      " 0.0000  0.1840 -0.1365\n",
      " 0.1193  0.0000 -0.1989\n",
      " 0.0281  0.0000 -0.1422\n",
      " 0.0074  0.0000 -0.0999\n",
      " 0.0000  0.5139 -0.1773\n",
      " 0.0000  0.4806 -0.1728\n",
      " 0.0000  0.0486 -0.1755\n",
      " 0.1231  0.0000 -0.2619\n",
      "[torch.FloatTensor of size 300x3]\n",
      "\n",
      "loss : Variable containing:\n",
      " 1.8318\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate validation set error\n",
    "#out = net(v_inp)\n",
    "# Calculate Loss\n",
    "out = net(x)\n",
    "loss = criterion(out, y)\n",
    "print(out[300:600],y[300:600])\n",
    "# print( out)\n",
    "# print( v_out)\n",
    "print(\"loss : \"+str(loss))\n",
    "# print('Epoch :',epoch, '  Error:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'trainedmodel_4timesalpine1_500hidden_3out(tanh)200it_standardmodel_savedasmodel'\n",
    "# https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n",
    "torch.save(model, save_path)\n",
    "# model.save_state_dict('trainedmodel_bbdata_500hidden_3out(tanh)_22in_500it_adam(hopefully_good_results.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = torch.load('trainedmodel_bbdata_500hidden_3out(tanh)_21in_1000it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "   -0.0101\n",
      "    1.0440\n",
      " 6313.7100\n",
      "    7.0576\n",
      "    1.0000\n",
      "    0.0000\n",
      "    7.0000\n",
      " 8935.3701\n",
      "   50.1658\n",
      "    0.0429\n",
      "   -0.0253\n",
      "    0.3401\n",
      "    0.2795\n",
      "   42.2622\n",
      "   41.8815\n",
      "   63.4362\n",
      "   63.4362\n",
      "    3.9594\n",
      "    4.9131\n",
      "    8.2495\n",
      "   14.0993\n",
      "   22.9128\n",
      "   35.5212\n",
      "   52.9234\n",
      "   76.0210\n",
      "  105.2300\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  147.3400\n",
      "   88.0843\n",
      "   52.6279\n",
      "   30.7736\n",
      "   17.4026\n",
      "   10.1312\n",
      "    8.0412\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "   29.8444\n",
      "   13.4412\n",
      "   21.8065\n",
      "    6.9078\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "  200.0000\n",
      "[torch.FloatTensor of size 72]\n",
      "\n",
      "Variable containing:\n",
      " 0.9859\n",
      "-0.0046\n",
      " 0.0030\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 1.0000\n",
      " 0.0000\n",
      " 0.0196\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value = x[100]\n",
    "\n",
    "print(value)\n",
    "print(net(value))\n",
    "print(y[100])\n",
    "# print(loss_fn(model(value),y[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
